{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "548e7922",
   "metadata": {},
   "source": [
    "## Probelm 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc78938",
   "metadata": {},
   "source": [
    "### 3a. Use the FashionMNIST training dataset (which we used in previous assign- ments) to train the DCGAN. Images are grayscale and size 28 Ã— 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f86c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1dbca7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## download the data\n",
    "train_data = torchvision.datasets.FashionMNIST('./FashionMNIST/',train=True,download=True,transform=torchvision.transforms.ToTensor())\n",
    "test_data = torchvision.datasets.FashionMNIST('./FashionMNIST/',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "image, label = trainingdata[0]\n",
    "print(image.size())\n",
    "\n",
    "plt.imshow(image.squeeze(), cmap=plt.cm.gray)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f6dfb",
   "metadata": {},
   "source": [
    "## 3b.\n",
    "\n",
    "Use the following discriminator architecture (kernel size = 5 Ã— 5 with stride = 2 in both directions):\n",
    "\n",
    "- 2D convolutions(1Ã—28Ã—28â†’64Ã—14Ã—14â†’128Ã—7Ã—7)\n",
    "- each convolutional layer is equipped with a Leaky ReLU with slope 0.3, followed by Dropout with parameter 0.3.\n",
    "- a dense layer that takes the flattened output of the last convolution and maps it to a scalar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6148fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_channels=1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2)\n",
    "        \n",
    "        # Define Leaky ReLU and Dropout\n",
    "        self.leaky_relu = nn.LeakyReLU(0.3)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Define the dense layer\n",
    "        self.dense = nn.Linear(128*7*7, 1)  # 128 channels, 7x7 feature map\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass through convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Flatten the output for the dense layer\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Forward pass through the dense layer\n",
    "        x = self.dense(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e4087f",
   "metadata": {},
   "source": [
    "## 2.c\n",
    "\n",
    "Use the following generator architecture (which is essentially the reverse of a standard discriminative architecture). You can use the same kernel size. Construct:\n",
    "\n",
    "- a dense layer that takes a unit Gaussian noise vector of length 100 and maps it to a vector of size $(7 \\times 7 \\times 256)$. No bias terms.\n",
    "- several transpose 2D convolutions $(256 \\times 7 \\times 7 \\rightarrow 128 \\times 7 \\times 7 \\rightarrow 64 \\times 14 \\times 14 \\rightarrow 1 \\times 28 \\times 28)$. No bias terms.\n",
    "- each convolutional layer (except the last one) is equipped with Batch Normalization (batch norm), followed by Leaky ReLU with slope $0.3$. The last (output) layer is equipped with tanh activation (no batch norm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8f06fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim=100, output_channels=1):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Define the dense layer\n",
    "        self.dense = nn.Linear(input_dim, 7*7*256, bias=False)\n",
    "        \n",
    "        # Define the transpose convolutional layers\n",
    "        self.conv1 = nn.ConvTranspose2d(256, 128, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.conv2 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2, padding=2, output_padding=1, bias=False)\n",
    "        self.conv3 = nn.ConvTranspose2d(64, output_channels, kernel_size=5, stride=2, padding=2, output_padding=1, bias=False)\n",
    "        \n",
    "        # Define batch normalization\n",
    "        self.batch_norm1 = nn.BatchNorm2d(128)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Define Leaky ReLU\n",
    "        self.leaky_relu = nn.LeakyReLU(0.3)\n",
    "        \n",
    "        # Define tanh activation\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass through the dense layer\n",
    "        x = self.dense(x)\n",
    "        x = x.view(-1, 256, 7, 7)  # Reshape to 4D tensor\n",
    "        \n",
    "        # Forward pass through transpose convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.tanh(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd11b16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16898ea50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the dimensionality of the noise vector\n",
    "noise_dim = 100\n",
    "\n",
    "# Create a random noise vector\n",
    "noise = torch.randn(1, noise_dim)\n",
    "\n",
    "# Instantiate the Generator\n",
    "generator = Generator(input_dim=noise_dim, output_channels=1)\n",
    "\n",
    "# Generate an image using the noise vector\n",
    "generated_image = generator(noise)\n",
    "\n",
    "random_img = generated_image.detach().numpy()\n",
    "# Display the generated image shape\n",
    "plt.imshow(random_img.squeeze(), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32c04d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20], Batch [0/1875], Discriminator Loss: 1.4178, Generator Loss: 0.9910\n",
      "Epoch [0/20], Batch [100/1875], Discriminator Loss: 0.0597, Generator Loss: 11.6814\n",
      "Epoch [0/20], Batch [200/1875], Discriminator Loss: 0.0567, Generator Loss: 6.8117\n",
      "Epoch [0/20], Batch [300/1875], Discriminator Loss: 0.0334, Generator Loss: 8.4362\n",
      "Epoch [0/20], Batch [400/1875], Discriminator Loss: 0.1008, Generator Loss: 13.4678\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m d_loss \u001b[38;5;241m=\u001b[39m d_loss_real \u001b[38;5;241m+\u001b[39m d_loss_fake\n\u001b[1;32m     64\u001b[0m d_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 65\u001b[0m d_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Train the generator\u001b[39;00m\n\u001b[1;32m     68\u001b[0m generator\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     adam(\n\u001b[1;32m    167\u001b[0m         params_with_grad,\n\u001b[1;32m    168\u001b[0m         grads,\n\u001b[1;32m    169\u001b[0m         exp_avgs,\n\u001b[1;32m    170\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    171\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    172\u001b[0m         state_steps,\n\u001b[1;32m    173\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    174\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    175\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    176\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    177\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    178\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    179\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    180\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    181\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    182\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    183\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    184\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    185\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    186\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m func(params,\n\u001b[1;32m    317\u001b[0m      grads,\n\u001b[1;32m    318\u001b[0m      exp_avgs,\n\u001b[1;32m    319\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    320\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    321\u001b[0m      state_steps,\n\u001b[1;32m    322\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    323\u001b[0m      has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    324\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    325\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    326\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    327\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    328\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    329\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    330\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m    331\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    332\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    333\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:441\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m--> 441\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(params[i]):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the parameters\n",
    "batch_size = 32\n",
    "noise_dim = 100\n",
    "lr = 10e-4\n",
    "num_epochs = 20\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5), (0.5,0.5))\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# Instantiate the discriminator and generator\n",
    "discriminator = Discriminator().to(device)\n",
    "generator = Generator(input_dim=noise_dim).to(device)\n",
    "\n",
    "# Define the loss function (binary cross-entropy)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "# Define optimizers\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=lr)\n",
    "\n",
    "# Training and testing loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real_images, _) in enumerate(train_loader):\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        \n",
    "        # Train the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        # Real images\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        real_output = discriminator(real_images)\n",
    "        d_loss_real = criterion(real_output, real_labels)\n",
    "        \n",
    "        # Fake images\n",
    "        noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "        fake_images = generator(noise)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        fake_output = discriminator(fake_images.detach())\n",
    "        d_loss_fake = criterion(fake_output, fake_labels)\n",
    "        \n",
    "        # Total discriminator loss\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # Train the generator\n",
    "        generator.zero_grad()\n",
    "        \n",
    "        noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "        fake_images = generator(noise).to(device)\n",
    "        labels = torch.ones(batch_size, 1).to(device)  # We want the generator to fool the discriminator\n",
    "        output = discriminator(fake_images)\n",
    "        g_loss = criterion(output, labels)\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        # Print progress every few batches\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}], Batch [{i}/{len(train_loader)}], \"\n",
    "                  f\"Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}\")\n",
    "        \n",
    "    # Save generated images at the end of each epoch\n",
    "    with torch.no_grad():\n",
    "        fake = generator(torch.randn(64, noise_dim)).to(device)\n",
    "        vutils.save_image(fake, f\"generated_images_epoch_{epoch+1}.png\", normalize=True)\n",
    "\n",
    "    # Visualize generated images for every few epochs\n",
    "    if epoch % 5 == 0:\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        generator.eval()\n",
    "        with torch.no_grad():\n",
    "            noise = torch.randn(25, noise_dim).to(device)\n",
    "            generated_images = generator(noise).cpu().detach()\n",
    "            for i in range(25):\n",
    "                plt.subplot(5, 5, i + 1)\n",
    "                plt.imshow(generated_images[i].view(28, 28), cmap='gray')\n",
    "                plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# Generate and visualize some images after training\n",
    "plt.figure(figsize=(8, 8))\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(25, noise_dim)\n",
    "    generated_images = generator(noise).cpu().detach()\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.imshow(generated_images[i].view(28, 28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
